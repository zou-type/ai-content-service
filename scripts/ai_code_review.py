#!/usr/bin/env python3
"""
AIä»£ç å®¡æŸ¥è„šæœ¬
è‡ªåŠ¨å®¡æŸ¥é£è·è½½è®¡ç®—é¡¹ç›®çš„ä»£ç è´¨é‡
"""

import os
import sys
import json
import ast
from pathlib import Path
from huggingface_ai_helper import HuggingFaceAI

def find_changed_files():
    """æŸ¥æ‰¾æ›´æ”¹çš„æ–‡ä»¶ï¼ˆç”¨äºPRå®¡æŸ¥ï¼‰"""
    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®¡æŸ¥æ‰€æœ‰Pythonæ–‡ä»¶
    return find_python_files("src")

def find_python_files(directory="src"):
    """æŸ¥æ‰¾Pythonæ–‡ä»¶"""
    python_files = []
    
    for root, dirs, files in os.walk(directory):
        for file in files:
            if file.endswith(".py"):
                python_files.append(Path(root) / file)
    
    return python_files

def analyze_code_structure(filepath, content):
    """åˆ†æä»£ç ç»“æ„"""
    try:
        tree = ast.parse(content)
        
        # æ”¶é›†ä¿¡æ¯
        functions = []
        classes = []
        imports = []
        
        for node in ast.walk(tree):
            if isinstance(node, ast.FunctionDef):
                functions.append({
                    "name": node.name,
                    "args": len(node.args.args),
                    "lineno": node.lineno,
                    "docstring": ast.get_docstring(node)
                })
            elif isinstance(node, ast.ClassDef):
                classes.append({
                    "name": node.name,
                    "lineno": node.lineno,
                    "docstring": ast.get_docstring(node)
                })
            elif isinstance(node, ast.Import):
                for alias in node.names:
                    imports.append(alias.name)
            elif isinstance(node, ast.ImportFrom):
                module = node.module or ""
                for alias in node.names:
                    imports.append(f"{module}.{alias.name}")
        
        return {
            "file": str(filepath),
            "functions": functions,
            "classes": classes,
            "imports": imports,
            "line_count": len(content.splitlines()),
            "char_count": len(content)
        }
    except SyntaxError as e:
        return {
            "file": str(filepath),
            "error": f"è¯­æ³•é”™è¯¯: {e}",
            "line_count": len(content.splitlines())
        }

def perform_ai_code_review(ai_helper, filepath, content, analysis):
    """æ‰§è¡ŒAIä»£ç å®¡æŸ¥"""
    print(f"å®¡æŸ¥ä»£ç : {filepath}")
    
    # å‡†å¤‡å®¡æŸ¥æç¤º
    prompt = f"""è¯·å¯¹ä»¥ä¸‹Pythonä»£ç è¿›è¡Œä¸“ä¸šä»£ç å®¡æŸ¥ï¼š

æ–‡ä»¶: {filepath}

ä»£ç å†…å®¹:
```python
{content[:2000]}  # é™åˆ¶é•¿åº¦
```

ä»£ç åˆ†æ:
{json.dumps(analysis, indent=2, ensure_ascii=False)}

å®¡æŸ¥è¦æ±‚:
1. ä»£ç è´¨é‡è¯„ä¼°
2. æ½œåœ¨é—®é¢˜å‘ç°
3. æ€§èƒ½ä¼˜åŒ–å»ºè®®
4. å®‰å…¨æ€§æ£€æŸ¥
5. å¯è¯»æ€§æ”¹è¿›
6. è§„èŒƒç¬¦åˆæ€§ï¼ˆPEP 8ï¼‰
7. å…·ä½“ä¿®æ”¹å»ºè®®

è¯·ç”¨ä¸­æ–‡å›å¤ï¼Œæ ¼å¼ï¼š
- âœ… ä¼˜ç‚¹
- âš ï¸  é—®é¢˜
- ğŸ”§ å»ºè®®
- ğŸ“ å…·ä½“ä¿®æ”¹

é’ˆå¯¹é£è·è½½è®¡ç®—é¡¹ç›®çš„ç‰¹æ®Šæ€§ï¼Œè¯·ç‰¹åˆ«å…³æ³¨ï¼š
- æ•°å€¼è®¡ç®—å‡†ç¡®æ€§
- é”™è¯¯å¤„ç†å®Œæ•´æ€§
- æ–‡æ¡£å®Œæ•´æ€§
- å·¥ç¨‹åº”ç”¨å¯é æ€§"""
    
    # è°ƒç”¨AIå®¡æŸ¥
    review = ai_helper.query(prompt, max_length=1500)
    
    if isinstance(review, list) and len(review) > 0:
        review_text = review[0].get("generated_text", "")
    elif isinstance(review, dict) and "generated_text" in review:
        review_text = review["generated_text"]
    else:
        review_text = str(review)
    
    return {
        "file": str(filepath),
        "analysis": analysis,
        "review": review_text,
        "has_issues": "âš ï¸" in review_text or "âŒ" in review_text or "é—®é¢˜" in review_text
    }

def generate_review_summary(ai_helper, all_reviews):
    """ç”Ÿæˆå®¡æŸ¥æ€»ç»“"""
    print("ç”Ÿæˆå®¡æŸ¥æ€»ç»“...")
    
    summary_data = {
        "total_files": len(all_reviews),
        "files_with_issues": sum(1 for r in all_reviews if r["has_issues"]),
        "total_functions": sum(len(r["analysis"].get("functions", [])) for r in all_reviews),
        "total_classes": sum(len(r["analysis"].get("classes", [])) for r in all_reviews),
        "reviews": all_reviews
    }
    
    # ç”Ÿæˆæ€»ç»“æç¤º
    prompt = f"""è¯·åŸºäºä»¥ä¸‹ä»£ç å®¡æŸ¥ç»“æœç”Ÿæˆé¡¹ç›®æ€»ç»“ï¼š

å®¡æŸ¥æ¦‚å†µ:
- å®¡æŸ¥æ–‡ä»¶æ•°: {summary_data['total_files']}
- å­˜åœ¨é—®é¢˜æ–‡ä»¶: {summary_data['files_with_issues']}
- æ€»å‡½æ•°æ•°: {summary_data['total_functions']}
- æ€»ç±»æ•°: {summary_data['total_classes']}

è¯¦ç»†å®¡æŸ¥ç»“æœ:
{json.dumps([r for r in all_reviews if r['has_issues']], indent=2, ensure_ascii=False)}

æ€»ç»“è¦æ±‚:
1. é¡¹ç›®æ•´ä½“ä»£ç è´¨é‡è¯„ä¼°
2. ä¸»è¦é—®é¢˜åˆ†ç±»
3. ä¼˜å…ˆçº§å»ºè®®ï¼ˆé«˜/ä¸­/ä½ï¼‰
4. æ”¹è¿›è·¯çº¿å›¾
5. æœ€ä½³å®è·µå»ºè®®

è¯·ç”¨ä¸“ä¸šçš„æŠ€æœ¯æŠ¥å‘Šæ ¼å¼ï¼Œé€‚åˆé¡¹ç›®ç®¡ç†è€…é˜…è¯»ã€‚"""
    
    summary = ai_helper.query(prompt, max_length=1000)
    
    if isinstance(summary, list) and len(summary) > 0:
        summary_text = summary[0].get("generated_text", "")
    elif isinstance(summary, dict) and "generated_text" in summary:
        summary_text = summary["generated_text"]
    else:
        summary_text = str(summary)
    
    return {
        "summary": summary_text,
        "data": summary_data
    }

def save_review_results(all_reviews, summary):
    """ä¿å­˜å®¡æŸ¥ç»“æœ"""
    # ä¿å­˜è¯¦ç»†å®¡æŸ¥ç»“æœ
    reviews_dir = Path("code_reviews")
    reviews_dir.mkdir(exist_ok=True)
    
    # ä¿å­˜æ¯ä¸ªæ–‡ä»¶çš„å®¡æŸ¥
    for review in all_reviews:
        filename = Path(review["file"]).name.replace(".py", "_review.md")
        review_file = reviews_dir / filename
        
        with open(review_file, 'w', encoding='utf-8') as f:
            f.write(f"# ä»£ç å®¡æŸ¥æŠ¥å‘Š: {review['file']}\n\n")
            f.write(f"**å®¡æŸ¥æ—¶é—´**: {os.path.getmtime(__file__)}\n")
            f.write(f"**æ–‡ä»¶å¤§å°**: {review['analysis'].get('line_count', 0)} è¡Œ\n\n")
            f.write("---\n\n")
            f.write(review["review"])
    
    # ä¿å­˜æ€»ç»“
    summary_file = reviews_dir / "SUMMARY.md"
    with open(summary_file, 'w', encoding='utf-8') as f:
        f.write("# ä»£ç å®¡æŸ¥é¡¹ç›®æ€»ç»“\n\n")
        f.write(summary["summary"])
    
    # ä¿å­˜JSONæ•°æ®
    data_file = reviews_dir / "review_data.json"
    with open(data_file, 'w', encoding='utf-8') as f:
        json.dump({
            "summary": summary,
            "reviews": all_reviews
        }, f, indent=2, ensure_ascii=False)
    
    # ç”ŸæˆGitHubè¯„è®ºæ ¼å¼
    if os.getenv("GITHUB_ACTIONS"):
        comments = []
        for review in all_reviews:
            if review["has_issues"]:
                # ç®€åŒ–è¯„è®ºå†…å®¹
                comment = {
                    "path": review["file"],
                    "line": 1,  # é»˜è®¤ç¬¬ä¸€è¡Œ
                    "body": f"## AIä»£ç å®¡æŸ¥å‘ç°çš„é—®é¢˜\n\n{review['review'][:500]}..."
                }
                comments.append(comment)
        
        with open("ai_review_comments.json", 'w', encoding='utf-8') as f:
            json.dump(comments, f, indent=2, ensure_ascii=False)
    
    return reviews_dir

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("AIä»£ç å®¡æŸ¥å·¥å…· - é£è·è½½è®¡ç®—é¡¹ç›®")
    print("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    hf_token = os.getenv("HF_TOKEN")
    if not hf_token:
        print("âŒ é”™è¯¯ï¼šæœªè®¾ç½®HF_TOKENç¯å¢ƒå˜é‡")
        print("è¯·åœ¨GitHub Secretsä¸­é…ç½®HF_TOKEN")
        sys.exit(1)
    
    # åˆ›å»ºAIåŠ©æ‰‹
    try:
        ai = HuggingFaceAI(api_token=hf_token)
        print("âœ… Hugging Face AIåŠ©æ‰‹å·²åˆå§‹åŒ–")
    except Exception as e:
        print(f"âŒ AIåŠ©æ‰‹åˆå§‹åŒ–å¤±è´¥: {e}")
        sys.exit(1)
    
    # æŸ¥æ‰¾Pythonæ–‡ä»¶
    print("\nğŸ” æŸ¥æ‰¾Pythonæ–‡ä»¶...")
    python_files = find_python_files("src")
    
    if not python_files:
        print("âš ï¸  æœªæ‰¾åˆ°srcç›®å½•ï¼Œå°è¯•å½“å‰ç›®å½•")
        python_files = find_python_files(".")
    
    print(f"æ‰¾åˆ° {len(python_files)} ä¸ªPythonæ–‡ä»¶")
    
    # æ‰§è¡Œä»£ç å®¡æŸ¥
    all_reviews = []
    for filepath in python_files:
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # åˆ†æä»£ç ç»“æ„
            analysis = analyze_code_structure(filepath, content)
            
            # AIå®¡æŸ¥
            review = perform_ai_code_review(ai, filepath, content, analysis)
            all_reviews.append(review)
            
            if review["has_issues"]:
                print(f"âš ï¸  å‘ç°é—®é¢˜: {filepath}")
            else:
                print(f"âœ… é€šè¿‡å®¡æŸ¥: {filepath}")
                
        except Exception as e:
            print(f"âŒ å®¡æŸ¥å¤±è´¥ {filepath}: {e}")
    
    # ç”Ÿæˆæ€»ç»“
    if all_reviews:
        summary = generate_review_summary(ai, all_reviews)
        
        # ä¿å­˜ç»“æœ
        output_dir = save_review_results(all_reviews, summary)
        
        print(f"\nâœ… ä»£ç å®¡æŸ¥å®Œæˆï¼")
        print(f"   å®¡æŸ¥æ–‡ä»¶æ•°: {len(all_reviews)}")
        print(f"   å‘ç°é—®é¢˜æ–‡ä»¶: {sum(1 for r in all_reviews if r['has_issues'])}")
        print(f"   è¾“å‡ºç›®å½•: {output_dir}/")
        print(f"   æ€»ç»“æ–‡ä»¶: {output_dir}/SUMMARY.md")
        
        # æ˜¾ç¤ºå…³é”®é—®é¢˜
        issues = [r for r in all_reviews if r["has_issues"]]
        if issues:
            print("\nğŸ“‹ å…³é”®é—®é¢˜æ–‡ä»¶:")
            for issue in issues[:5]:  # æ˜¾ç¤ºå‰5ä¸ª
                print(f"   - {issue['file']}")
    else:
        print("âŒ æœªå®Œæˆä»»ä½•ä»£ç å®¡æŸ¥")

if __name__ == "__main__":
    main()